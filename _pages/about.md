---
layout: about
title: Home
permalink: /
subtitle: # <a href='#'>Affiliations</a>. Address. Contacts. Moto. Etc.

profile:
  align: right
  image: prof_pic.jpg
  image_circular: false # crops the image to make it circular
  more_info: >
    <p>...</p>
    
news: true # includes a list of news items
latest_posts: false # includes a list of the newest posts
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page
---

Hi! I am a PhD student at Purdue ECE where I work with [David I. Inouye](https://www.davidinouye.com/). 

Essentially speaking, I am seeking to answer the question: **"How can we make machine learning more 
robust and reliable?"**

More specifically, I am interested in understanding the following questions:

(1) *How can we make machine learning models more robust to distribution shift?*

(2) How can we make machine learning models more trustworthy (e.g., fair, interpretable, and reliable)?

(3) How can we make machine learning models more reliable by understanding the underlying causal mechanisms?

(4) How can we make machine learning models more reliable by understanding the underlying data generation process?

To answer these questions, I have leverage tools including (1) casusality ([ICLR24](https://openreview.net/forum?id=v1VvCWJAL))
(2) generative models ([ICLR23](https://openreview.net/forum?id=uhLAcrAZ9cJ), [AISTATS22](https://proceedings.mlr.press/v151/zhou22b)) 






My research keywords are as follows:

(1) Distribution Shift

(2) Trustworthy ML (robustness, fairness)

(3) Causality

(4) Generative Models

I have a track record of publishing in top conferences like ICLR and AISTATS, and industry research experience at Amazon and Bloomberg.

üßêÔ∏è**I am looking for a research internship in Summer/Fall 2024. Please let me know if you have any opening.**

Feel free to drop me an email if you are interested in my research or just want to chat. I am always open to new ideas and collaborations.